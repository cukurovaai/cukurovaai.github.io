<!DOCTYPE html> <html lang="tr"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Video Stabilizasyon İşlemi İçin Öz Gözetimli Derin Öğrenme Yaklaşımı | Çukurova AI</title> <meta name="author" content="Çukurova AI"> <meta name="description" content="projects.descriptions.video_stabilization"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/brain.png"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://cukurovaai.github.io/projects/video_stabilization/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/tr/"><span class="font-weight-bold">Çukurova </span>AI</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/tr/">Hakkımızda</a> </li> <li class="nav-item "> <a class="nav-link" href="/tr/publications/">Yayınlar</a> </li> <li class="nav-item "> <a class="nav-link" href="/tr/projects/">Projeler</a> </li> <li class="nav-item "> <a class="nav-link" href="/tr/team/">Ekibimiz</a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/video_stabilization/">EN</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Video Stabilizasyon İşlemi İçin Öz Gözetimli Derin Öğrenme Yaklaşımı</h1> <p class="post-description">ARDEB 3501</p> </header> <article> <p><strong>Mehmet SARIGÜL (Yürütücü)</strong>, Levent KARACAN</p> <p><strong>Abstract:</strong> In video recordings taken with mobile devices such as handheld cameras, head cameras, mobile phones, undesired visual effects are formed such as shaking, flickering or periodic camera movements. The processes that eliminate these undesired effects are called as video stabilization. With the need to shoot video from moving platforms such as cars, unmanned aircrafts, wearable devices, the need for inexpensive and effective video stabilization has also increased. Although certain types of high-frequency motion effects can be eliminated with special equipment placed on camera systems, these equipment are both expensive and power consuming. In addition, motion range and degrees of freedom are limited in these systems. To overcome these limitations, computer vision methods basically try to estimate undesired motion between video frames by tracking various types of visual features, and then they correct camera path by warping scenes according to the estimated motion. In these methods, selecting the correct visual features and tracking algorithm is crucial for the performance of the method. As a result, the problem arises of determining which feature extractors and tracking algorithms should be used for different types of scenes. Unlike these methods that are difficult to adapt to new types of scenes and costly in terms of computation, learning-based methods have been developed. in recent years. However, these works use supervised learning methods that need a dataset containing a limited number of scenes with both stable and unstable pairs of the same scene obtained with special equipment. Hence, obtained models are dataset dependent and cannot be easily adapted to new scenes in different context and semantics.</p> <p>In this project, we will explore to use unsupervised learning techniques on a video processing problem. More specifically, a novel self-supervised video stabilization method which does not require stable video supervision during training will be developed to overcome the dataset barrier in recent supervised learning methods and fill the gap of unsupervised video stabilization. Producing new dataset with proper labels is expensive and time-consuming even though abundance of unlabeled data. With this research, we will demonstrate that camera movements for video stabilization can be generated synthetically from the data itself and this can be used for training. The goal with this new self-supervised learning approach is to develop a new video stabilization model which is faster and more robust than previous non-learning-based methods and also more generalizable and more successful than deep supervised learning-based approaches which require stable video supervision. For this purpose, we will first study on learning the visual features required to distinguish desired and undesired motions in videos. Then, with the help of these visual features, a suitable self-supervised learning method will be investigated so that transformations that cause undesired motions will be predicted. In the last stage, we will develop a novel video to video translation model which translates unstable input videos to stable videos using conditional Generative Adversarial Network conditioned by predicted transformations.</p> <p>The video stabilization is closely related with many other computer vision problems such as video classification, video generation, future frame prediction, motion detection, etc. Therefore, various knowledge, skills and experience related to all these problems will be gained, new researchers will be trained on related problems and thesis studies will be conducted. The video stabilization method will be developed can be used in various industrial areas such as automotive, defense industry, healthcare industry, etc. This project has also high potential to lead new projects.</p> <p><a href="https://videostab.github.io/" rel="external nofollow noopener" target="_blank">videostab.github.io</a>.</p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Çukurova AI </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>